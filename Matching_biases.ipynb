{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the code for the notebook demonstrating how the matching is performed in the thesis. First,  a setting is created which resembles the GRM in grmpy, meaning data are simulated accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the beginning, a couple of packages need to be installed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymatch in ./anaconda3/lib/python3.7/site-packages (0.3.4)\n",
      "Requirement already satisfied: pandas==0.23.4 in ./anaconda3/lib/python3.7/site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in ./anaconda3/lib/python3.7/site-packages (from pandas==0.23.4) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in ./anaconda3/lib/python3.7/site-packages (from pandas==0.23.4) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.9.0 in ./anaconda3/lib/python3.7/site-packages (from pandas==0.23.4) (1.16.2)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas==0.23.4) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "#install pymatch and due to a bug pandas needs to be downgraded...\n",
    "!pip install pymatch\n",
    "!pip install pandas==0.23.4\n",
    "#import packages\n",
    "import numpy\n",
    "import math\n",
    "import numpy.random as nprand\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot as plt\n",
    "from pymatch.Matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the dataset is generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_var(num):\n",
    "    NumAgents = num\n",
    "    mean = [0,0,0]\n",
    "#correlation between x, theta_cog and theta_soc assumed to be zero in the first place\n",
    "    correlation1 = 0\n",
    "    correlation2 = 0\n",
    "    correlation12 = 0\n",
    "    cov = [[1,correlation1,correlation2],[correlation1,1,correlation12],[correlation2, correlation12, 1]]\n",
    "    test = nprand.multivariate_normal(mean,cov,NumAgents)\n",
    "    df_test = pd.DataFrame(data=test, columns=['x','theta_cog','theta_soc'])\n",
    "    df_test['constant'] = ([1,]*NumAgents)\n",
    "    df_test['index']=df_test.index\n",
    "    theta_cog = df_test['theta_cog']\n",
    "    theta_soc = df_test['theta_soc']\n",
    "    x = df_test['x']\n",
    "#creation of measurements\n",
    "    theta_line_cog = numpy.column_stack((theta_cog,theta_cog,theta_cog,theta_cog))\n",
    "    theta_line_soc = numpy.column_stack((theta_soc,theta_soc,theta_soc,theta_soc))\n",
    "    jota_cog = ([[1,1,1,1],]*NumAgents)\n",
    "    #jota_soc = ([[0.9,0.9,0.9,0.9],]*NumAgents)\n",
    "    jota_soc = ([[1,1,1,1],]*NumAgents)\n",
    "    delta = ([[0,0,0,0],]*NumAgents)\n",
    "    x_row = numpy.column_stack((x,x,x,x))\n",
    "    v1 = randn(NumAgents)\n",
    "    v2 = randn(NumAgents)\n",
    "    v3 = randn(NumAgents)\n",
    "    v4 = randn(NumAgents)\n",
    "    epsilon = numpy.column_stack((v1,v2,v3,v4))\n",
    "    measurement = numpy.multiply(jota_cog,theta_line_cog) + numpy.multiply(jota_soc,theta_line_soc)+ numpy.multiply(delta,x_row) + epsilon\n",
    "    df_m = pd.DataFrame(data=measurement, columns=['M1','M2','M3','M4'])\n",
    "    df_m['index'] = df_m.index\n",
    "    df = df_test.merge(df_m, on='index')\n",
    "# creation unobservables\n",
    "    mean_unobs = [0,0,0]\n",
    "#correlation in the unobverables ==> assumed to be 0\n",
    "    rho_1 = 0\n",
    "    rho_2 = 0\n",
    "    cov_unobs = [[1,0,rho_1],[0,1,rho_2],[rho_1,rho_2,1]]\n",
    "    unobs = nprand.multivariate_normal(mean_unobs,cov_unobs,NumAgents)\n",
    "    df_unobs = pd.DataFrame(data=unobs, columns=['u1','u0','uc'])\n",
    "    df_unobs['index'] = df_unobs.index\n",
    "    df = df.merge(df_unobs, on='index')\n",
    "# creation outcomes\n",
    "    df['Y1'] = 1*df['constant'] + 0*df['x'] +  2*df['theta_cog']+ 0.1*df['theta_soc']+df['u1']\n",
    "    df['Y0'] = 0*df['constant'] + 0*df['x'] + 1*df['theta_cog'] + 0.1*df['theta_soc'] + df['u0']\n",
    "    df['x3'] = randn(NumAgents)\n",
    "# model structure can be choosen freely\n",
    "    #df['cost'] =  1.1*df['constant'] + -0.39*df['x3'] + 0.52*df['theta_soc'] + -0.58*df['theta_cog']+ df['uc']\n",
    "    df['cost'] =  0*df['constant'] + 1*df['x3'] - 0.5*df['theta_soc'] + 0.5*df['theta_cog']+ df['uc']\n",
    "    #df['expected_benefit'] = (df['cost'])\n",
    "    df['expected_benefit'] = ((df['Y1'] - df['u1']) - (df['Y0'] - df['u0'])) - (df['cost'])\n",
    "    df['D'] = 0\n",
    "    df.loc[df.expected_benefit > 0, 'D'] = 1\n",
    "    df['D_1'] = 0\n",
    "    df.loc[df.D == 0, 'D_1'] = 1\n",
    "    df['Y'] = df.Y1\n",
    "    df.loc[df['D'] == 0, 'Y'] = df.Y0 \n",
    "    test = df.groupby('D').mean()\n",
    "    benefit = df['Y1'] - df['Y0']\n",
    "# define effects\n",
    "    TT = numpy.mean(df[df.D == 1][\"Y1\"] - df[df.D == 1][\"Y0\"])\n",
    "    ATE = numpy.mean(benefit)\n",
    "    TUT = numpy.mean(df[df.D == 0][\"Y1\"] - df[df.D == 0][\"Y0\"])\n",
    "# build data sets\n",
    "    treatment_t = df[df.D == 1]\n",
    "    control_t = df[df.D == 0]\n",
    "    return treatment_t, control_t, ATE, TT, TUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the matching needs to be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching in order to identify the ATE\n",
    "#defining the information sets\n",
    "relevant=['level_0','u0','index','constant','M1','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','D_1']\n",
    "minimal=['level_0','u0','index','constant','M1','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','x3','D_1']\n",
    "only_theta_cog = ['level_0','u0','index','constant','theta_soc','M1','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','D_1']\n",
    "only_M1 = ['level_0','u0','index','constant','theta_soc','theta_cog','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','D_1']\n",
    "only_x3 = ['level_0','u0','index','constant','theta_soc','theta_cog','M1','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','D_1']\n",
    "def matching_all(num, Buchstabe):\n",
    "#simulate data set    \n",
    "    data = cov_var(num)\n",
    "    a = data[0]\n",
    "    b = data[1]\n",
    "#calibartaing the matcher\n",
    "    m=Matcher(a,b,yvar='D',exclude=Buchstabe)\n",
    "#predict scores\n",
    "    m.fit_scores(balance=True, nmodels=20)\n",
    "    m.predict_scores()\n",
    "    m.plot_scores()\n",
    "#perform matching\n",
    "    m.match(method=\"random\", nmatches=1, threshold=0.0001)\n",
    "    m.record_frequency()\n",
    "    m.assign_weight_vector()\n",
    "    df=m.matched_data\n",
    "    cc = m.compare_continuous(return_table=True)\n",
    "#for TUT\n",
    "    m_2=Matcher(b,a,yvar='D',exclude=['level_0','u0','index','constant','M1','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','D_1'])\n",
    "    m_2.fit_scores(balance=True, nmodels=20)\n",
    "    m_2.predict_scores()\n",
    "    m_2.plot_scores()\n",
    "    m_2.match(method=\"random\", nmatches=1, threshold=0.0001)\n",
    "    m_2.record_frequency()\n",
    "    m_2.assign_weight_vector()\n",
    "    df_2=m_2.matched_data\n",
    "    cc_2 = m_2.compare_continuous(return_table=True)\n",
    "#TT\n",
    "    TT = numpy.mean(df[df.D == 1][\"Y\"]) -  numpy.mean(df[df.D == 0][\"Y\"])- data[3]\n",
    "#TUT\n",
    "    TUT = numpy.mean(df_2[df_2.D == 1][\"Y\"]) -  numpy.mean(df_2[df_2.D == 0][\"Y\"])- data[4]\n",
    "#ATE    \n",
    "    return (len(a)/num)*TT + (len(b)/num)*TUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching in order to identify TT\n",
    "def matching_all(num, rho_1, rho_2, Buchstabe):\n",
    "    data = cov_var(num, rho_1, rho_2, Buchstabe)\n",
    "    a = data[0]\n",
    "    b = data[1]\n",
    "    m=Matcher(a,b,yvar='D',exclude=['level_0','u0','index','constant','M1','M2','M3','M4','u1','u2','uc','Y1','Y0','cost','experinced','Y','pred_values','expected_benefit','x','D_1'])\n",
    "    m.fit_scores(balance=True, nmodels=100)\n",
    "    m.predict_scores()\n",
    "    m.plot_scores()\n",
    "    m.match(method=\"random\", nmatches=1, threshold=0.0001)\n",
    "    m.record_frequency()\n",
    "    m.assign_weight_vector()\n",
    "    df=m.matched_data\n",
    "    cc = m.compare_continuous(return_table=True)\n",
    "    return numpy.mean(df[df.D == 1][\"Y\"]) -  numpy.mean(df[df.D == 0][\"Y\"])- data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last but not least, the code for the OLS is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_1 = 'Y ~ D + x + x3+ theta_cog+ theta_soc'\n",
    "W_1 = 'Y ~ D + x + theta_cog+ theta_soc'\n",
    "X_1 = 'Y ~ D + x + x3 + theta_cog'\n",
    "Y_1 = 'Y ~ D + x + x3 + M1'\n",
    "Z_1 = 'Y ~ D + x + x3'\n",
    "def cov_var(num):\n",
    "    NumAgents = num\n",
    "    mean = [0,0,0]\n",
    "#correlation between x, theta_cog and theta_soc assumed to be zero in the first place\n",
    "    correlation1 = 0\n",
    "    correlation2 = 0\n",
    "    correlation12 = 0\n",
    "    cov = [[1,correlation1,correlation2],[correlation1,1,correlation12],[correlation2, correlation12, 1]]\n",
    "    test = nprand.multivariate_normal(mean,cov,NumAgents)\n",
    "    df_test = pd.DataFrame(data=test, columns=['x','theta_cog','theta_soc'])\n",
    "    df_test['constant'] = ([1,]*NumAgents)\n",
    "    df_test['index']=df_test.index\n",
    "    theta_cog = df_test['theta_cog']\n",
    "    theta_soc = df_test['theta_soc']\n",
    "    x = df_test['x']\n",
    "#creation of measurements\n",
    "    theta_line_cog = numpy.column_stack((theta_cog,theta_cog,theta_cog,theta_cog))\n",
    "    theta_line_soc = numpy.column_stack((theta_soc,theta_soc,theta_soc,theta_soc))\n",
    "    jota_cog = ([[1,1,1,1],]*NumAgents)\n",
    "    #jota_soc = ([[0.9,0.9,0.9,0.9],]*NumAgents)\n",
    "    jota_soc = ([[1,1,1,1],]*NumAgents)\n",
    "    delta = ([[0,0,0,0],]*NumAgents)\n",
    "    x_row = numpy.column_stack((x,x,x,x))\n",
    "    v1 = randn(NumAgents)\n",
    "    v2 = randn(NumAgents)\n",
    "    v3 = randn(NumAgents)\n",
    "    v4 = randn(NumAgents)\n",
    "    epsilon = numpy.column_stack((v1,v2,v3,v4))\n",
    "    measurement = numpy.multiply(jota_cog,theta_line_cog) + numpy.multiply(jota_soc,theta_line_soc)+ numpy.multiply(delta,x_row) + epsilon\n",
    "    df_m = pd.DataFrame(data=measurement, columns=['M1','M2','M3','M4'])\n",
    "    df_m['index'] = df_m.index\n",
    "    df = df_test.merge(df_m, on='index')\n",
    "# creation unobservables\n",
    "    mean_unobs = [0,0,0]\n",
    "#correlation in the unobverables ==> assumed to be 0\n",
    "    rho_1 = 0\n",
    "    rho_2 = 0\n",
    "    cov_unobs = [[1,0,rho_1],[0,1,rho_2],[rho_1,rho_2,1]]\n",
    "    unobs = nprand.multivariate_normal(mean_unobs,cov_unobs,NumAgents)\n",
    "    df_unobs = pd.DataFrame(data=unobs, columns=['u1','u0','uc'])\n",
    "    df_unobs['index'] = df_unobs.index\n",
    "    df = df.merge(df_unobs, on='index')\n",
    "# creation outcomes\n",
    "    df['Y1'] = 1*df['constant'] + 0*df['x'] +  2*df['theta_cog']+ 0.1*df['theta_soc']+df['u1']\n",
    "    df['Y0'] = 0*df['constant'] + 0*df['x'] + 1*df['theta_cog'] + 0.1*df['theta_soc'] + df['u0']\n",
    "    df['x3'] = randn(NumAgents)\n",
    "# model structure can be choosen freely\n",
    "    #df['cost'] =  1.1*df['constant'] + -0.39*df['x3'] + 0.52*df['theta_soc'] + -0.58*df['theta_cog']+ df['uc']\n",
    "    df['cost'] =  0*df['constant'] + 1*df['x3'] - 0.5*df['theta_soc'] + 0.5*df['theta_cog']+ df['uc']\n",
    "#choose which cost function should be caluclated    \n",
    "    #df['expected_benefit'] = (df['cost'])\n",
    "    df['expected_benefit'] = ((df['Y1'] - df['u1']) - (df['Y0'] - df['u0'])) - (df['cost'])\n",
    "    df['D'] = 0\n",
    "    df.loc[df.expected_benefit > 0, 'D'] = 1\n",
    "    df['D_1'] = 0\n",
    "    df.loc[df.D == 0, 'D_1'] = 1\n",
    "    df['Y'] = df.Y1\n",
    "    df.loc[df['D'] == 0, 'Y'] = df.Y0 \n",
    "    test = df.groupby('D').mean()\n",
    "    benefit = df['Y1'] - df['Y0']\n",
    "# define effects\n",
    "    TT = numpy.mean(df[df.D == 1][\"Y1\"] - df[df.D == 1][\"Y0\"])\n",
    "    ATE = numpy.mean(benefit)\n",
    "    TUT = numpy.mean(df[df.D == 0][\"Y1\"] - df[df.D == 0][\"Y0\"])\n",
    "# build data sets\n",
    "    treatment_t = df[df.D == 1]\n",
    "    control_t = df[df.D == 0]\n",
    "#perform OLS\n",
    "    OLS_psm = smf.ols(Buchstabe, data=df)\n",
    "    results_OLS = OLS_psm.fit()\n",
    "    c = results_OLS.params[1]\n",
    "#calculate bias\n",
    "    return c - ATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
